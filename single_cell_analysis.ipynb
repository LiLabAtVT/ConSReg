{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "This Jupyter notebook walks through the basic functionalities of ConSReg that allow for building regulatory networks, and prioritizing important transcription factors (TFs) from the integration of DAP-seq, ATAC-seq and single cell RNA-seq data. Datasets used in this analysis are listed below:\n",
    "\n",
    "1. DAP-seq: [O'Malley et al., 2016](https://www.ncbi.nlm.nih.gov/pubmed/27203113)\n",
    "2. ATAC-seq: [Lu et al., 2017](https://academic.oup.com/nar/article/45/6/e41/2605943)\n",
    "3. single cell RNA-seq: [Ryu et al., 2019](https://www.ncbi.nlm.nih.gov/pubmed/30718350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "from ConSReg.main import ConSReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps for single cell analysis are the same with bulk analysis. The only difference here is the input data and type of negative training genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File names of input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dap-seq narrow peak files\n",
    "dap_file_list = os.listdir(\"data/dap_seq_all_peaks/\")\n",
    "dap_files = [ \"data/dap_seq_all_peaks/\" + file for file in dap_file_list if re.match(\".*narrowPeak\",file) is not None]\n",
    "\n",
    "# ATAC-seq peak file\n",
    "atac_file = \"data/atac_seq_all_peaks/all_merged.bed\"\n",
    "\n",
    "# Arabidopsis genome annotation file\n",
    "gff_file = \"data/TAIR10_GFF3_genes.gff\"\n",
    "\n",
    "# Differential contrast result\n",
    "sc_diff_file = [\"data/diff_single_cell/cortext-endodermis.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and preprocess all data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging DAP-seq peaks...\n",
      "Done\n",
      "Assigning CREs to nearest genes...\n",
      "Done\n",
      "Overlapping CREs with ATAC-seq...\n",
      "Done\n",
      "Reading diff tables...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConSReg.main.ConSReg at 0x7fec96857588>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis = ConSReg()\n",
    "\n",
    "# Specify parameters for preprocessing\n",
    "params = {\n",
    "    'dap_files':dap_files,\n",
    "    'diff_files':sc_diff_file,\n",
    "    'atac_file':atac_file,\n",
    "    'gff_file':gff_file,\n",
    "    'dap_chr_col':0,\n",
    "    'dap_chr_start_col':1,\n",
    "    'dap_chr_end_col':2,\n",
    "    'dap_strand_col':None,\n",
    "    'dap_signal_col':None,\n",
    "    'atac_chr_col':0,\n",
    "    'atac_chr_start_col':1, \n",
    "    'atac_chr_end_col':2,\n",
    "    'atac_signal_col':None,\n",
    "    'up_tss':3000,\n",
    "    'down_tss':500,\n",
    "    'up_type':'all', \n",
    "    'down_type':'all',\n",
    "    'use_peak_signal':False,\n",
    "    'n_jobs':16,\n",
    "    'verbose':True\n",
    "}\n",
    "analysis.preprocess(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate feature matrices for each differential contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing feature matrices will be overwritten.\n",
      "Generating feature matrices...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConSReg.main.ConSReg at 0x7fec96857588>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.gen_feature_mat(neg_type = 'udg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute AUC-ROC and AUC-PRC from corss-validation (CV) using LRLASSO method. Mean and standard deviation of AUC-ROC and AUC-PRC were reporeted from five replicates of CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cross-validation for each feature matrix using lrlasso engine...\n",
      "Old evaluation results will be ovewritten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConSReg.main.ConSReg at 0x7fec96857588>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.eval_by_cv(ml_engine = 'lrlasso',rep = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diff_name</th>\n",
       "      <th>auroc_mean_UR</th>\n",
       "      <th>auroc_std_UR</th>\n",
       "      <th>auroc_mean_DR</th>\n",
       "      <th>auroc_std_DR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cortext-endodermis.csv</td>\n",
       "      <td>0.654879</td>\n",
       "      <td>0.029298</td>\n",
       "      <td>0.604074</td>\n",
       "      <td>0.023465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diff_name  auroc_mean_UR  auroc_std_UR  auroc_mean_DR  \\\n",
       "0  cortext-endodermis.csv       0.654879      0.029298       0.604074   \n",
       "\n",
       "   auroc_std_DR  \n",
       "0      0.023465  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing importance scores will be overwritten.\n",
      "Performing stability selection and compute importance score for each TF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=36)]: Done   5 out of  10 | elapsed:    4.8s remaining:    4.8s\n",
      "[Parallel(n_jobs=36)]: Done  10 out of  10 | elapsed:    4.9s finished\n",
      "[Parallel(n_jobs=36)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=36)]: Done 128 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=36)]: Done 200 out of 200 | elapsed:    5.7s finished\n",
      "[Parallel(n_jobs=36)]: Using backend LokyBackend with 36 concurrent workers.\n",
      "[Parallel(n_jobs=36)]: Done   5 out of  10 | elapsed:    1.3s remaining:    1.3s\n",
      "[Parallel(n_jobs=36)]: Done  10 out of  10 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=36)]: Using backend LokyBackend with 36 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=36)]: Done 200 out of 200 | elapsed:    2.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConSReg.main.ConSReg at 0x7fec96857588>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.compute_imp_score(n_resampling = 200, n_jobs = 36, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing networks will be overwritten.\n",
      "Generating networks...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ConSReg.main.ConSReg at 0x7fec96857588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.gen_networks(imp_cutoff = 0.5, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save analysis result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation result\n",
    "analysis.auroc.to_csv(\"results/single_cell_analysis/auroc_result.csv\")\n",
    "analysis.auprc.to_csv(\"results/single_cell_analysis/auprc_result.csv\")\n",
    "\n",
    "# Importance scores\n",
    "analysis.imp_scores_UR.to_csv(\"results/single_cell_analysis/imp_score_UR.csv\")\n",
    "analysis.imp_scores_DR.to_csv(\"results/single_cell_analysis/imp_score_DR.csv\")\n",
    "\n",
    "# Networks were saved in the format of edge list\n",
    "for diff_name, network in zip(analysis._diff_name_list, analysis.networks_UR):\n",
    "    network.to_csv(\"results/single_cell_analysis/{}_UR_network.csv\".format(diff_name))\n",
    "    \n",
    "for diff_name, network in zip(analysis._diff_name_list, analysis.networks_DR):\n",
    "    network.to_csv(\"results/single_cell_analysis/{}_DR_network.csv\".format(diff_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
